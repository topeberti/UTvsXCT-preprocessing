{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tifffile\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "import os\n",
    "import pandas as pd\n",
    "import sys\n",
    "sys.path.append(r'\\\\192.168.10.106\\imdea\\DataDriven_UT_AlbertoVicente\\10_code\\UTvsXCT-preprocessing')\n",
    "import dbtools as db\n",
    "from preprocess_tools import io, sample_isolater"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Database conection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    conn = db.connect()\n",
    "    print(\"Connected to the database\")\n",
    "except Exception as error:\n",
    "    print(error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have to load the data from the database to get:\n",
    "\n",
    "1. The file ids to use them as parent measurement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measurements file paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_paths = [Path(r'\\\\192.168.10.106\\imdea\\DataDriven_UT_AlbertoVicente\\02_XCT_data\\Juan Ignacio\\medidas\\JI_4+5+7+8\\volumen_eq')]\n",
    "\n",
    "measurements_table = db.relation_metadata('measurements','samples','sample_measurements')\n",
    "\n",
    "parent_id_column = 'measurementtype_id_measurement'\n",
    "\n",
    "saving_folder = Path(r'\\\\192.168.10.106\\imdea\\DataDriven_UT_AlbertoVicente\\02_XCT_data\\Juan Ignacio\\probetas')\n",
    "\n",
    "# for each original path, get the id_measurement where file_path_measurement is equal to the str of the original path\n",
    "\n",
    "original_ids = []\n",
    "original_measurementtype_ids = []\n",
    "original_sample_names = []\n",
    "\n",
    "for original_path in original_paths:\n",
    "    original_path_str = str(original_path)\n",
    "    original_id = measurements_table.loc[measurements_table['file_path_measurement'] == original_path_str, 'id_measurement'].values\n",
    "    original_measurementtype_id = measurements_table.loc[measurements_table['file_path_measurement'] == original_path_str, parent_id_column].values[0]\n",
    "    original_sample_name = measurements_table.loc[measurements_table['file_path_measurement'] == original_path_str, 'name_sample'].values\n",
    "    original_ids.append(original_id)\n",
    "    original_measurementtype_ids.append(original_measurementtype_id)\n",
    "    original_sample_names.append(original_sample_name)\n",
    "    print(f\"Original path: {original_path_str}, ID: {original_id}\", \n",
    "          f\"Measurement type ID: {original_measurementtype_id}\",\n",
    "          f\"Sample names: {original_sample_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Database loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_measurement(file,file_path,parent_id,measurementtype_id,sample_names):\n",
    "\n",
    "    parent_id_column = 'measurementtype_id'\n",
    "\n",
    "    main_parameters = {'file_path':file_path,parent_id_column:measurementtype_id,'parent_measurement_id':parent_id}\n",
    "\n",
    "    # metadata\n",
    "\n",
    "    #for each parameter of the measurement a metadata has to be created\n",
    "\n",
    "    metadata_parameters = []\n",
    "\n",
    "    #dimensions\n",
    "    metadata_parameters.append({'key':'height', 'value':str(file.shape[0]), 'type':'cardinal'})\n",
    "\n",
    "    metadata_parameters.append({'key':'width', 'value':str(file.shape[1]), 'type':'cardinal'})\n",
    "\n",
    "    metadata_parameters.append({'key':'depth', 'value':str(file.shape[2]), 'type':'cardinal'})\n",
    "\n",
    "    #dtype\n",
    "\n",
    "    metadata_parameters.append({'key':'dtype', 'value':str(file.dtype), 'type':'nominal'})\n",
    "\n",
    "    #############################################################################################\n",
    "\n",
    "    #MANUAL PARAMETERS\n",
    "\n",
    "    #file type\n",
    "\n",
    "    metadata_parameters.append({'key':'file_type', 'value':'folder', 'type':'nominal'})\n",
    "\n",
    "    #aligned\n",
    "\n",
    "    metadata_parameters.append({'key':'aligned', 'value':'False', 'type':'boolean'})\n",
    "\n",
    "    #equalized\n",
    "\n",
    "    metadata_parameters.append({'key':'equalized', 'value':'True', 'type':'boolean'})\n",
    "\n",
    "    #axes\n",
    "    metadata_parameters.append({'key':'axes', 'value':'x,y,z', 'type':'nominal'})\n",
    "\n",
    "    print('Parameters to be inserted: ')\n",
    "    for key, value in main_parameters.items():\n",
    "        print(f\"-    {key}: {value}\")\n",
    "\n",
    "    table_name = 'measurements'\n",
    "\n",
    "    # Extract column names and values from the attributes dictionary\n",
    "    columns = ', '.join(main_parameters.keys())\n",
    "    values = ', '.join([f\"'{v}'\" for v in main_parameters.values()])\n",
    "\n",
    "    # Construct the SQL INSERT statement\n",
    "    sql = f\"INSERT INTO {table_name} ({columns}) VALUES ({values})\"\n",
    "\n",
    "    print(sql)\n",
    "\n",
    "    # Create a cursor object using the cursor() method\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    # Execute the SQL statement\n",
    "    cursor.execute(sql)\n",
    "\n",
    "    cursor.execute('COMMIT')\n",
    "\n",
    "    cursor.close()\n",
    "\n",
    "    data = db.get_data(table_name)\n",
    "\n",
    "    data[data['file_path_measurement'] == str(file_path)]\n",
    "\n",
    "    row_id = data['id_measurement'].values[-1]\n",
    "\n",
    "    metadata_table_name =  table_name[:-1] + '_metadata'\n",
    "\n",
    "    for attributes in metadata_parameters:\n",
    "\n",
    "        attributes[table_name[:-1] + '_id'] = row_id\n",
    "\n",
    "        # Extract column names and values from the attributes dictionary\n",
    "        columns = ', '.join(attributes.keys())\n",
    "        values = ', '.join([f\"'{v}'\" for v in attributes.values()])\n",
    "\n",
    "        # Construct the SQL INSERT statement\n",
    "        sql = f\"INSERT INTO {metadata_table_name} ({columns}) VALUES ({values})\"\n",
    "\n",
    "        print(sql)\n",
    "\n",
    "        # Create a cursor object using the cursor() method\n",
    "        cursor = conn.cursor()\n",
    "\n",
    "        # Execute the SQL statement\n",
    "        cursor.execute(sql)\n",
    "\n",
    "        cursor.execute('COMMIT')\n",
    "\n",
    "        cursor.close()\n",
    "    \n",
    "    samples_data = db.get_data_metadata('samples')\n",
    "\n",
    "    #get the ids of the samples in sample_names\n",
    "    samples_data = samples_data[samples_data['name_sample'].isin(sample_names)]\n",
    "\n",
    "    sample_ids = samples_data['id_sample'].values.tolist()\n",
    "\n",
    "    relational_table_name = 'sample_measurements'\n",
    "\n",
    "    for sample_id in sample_ids:\n",
    "\n",
    "        relational_parameters = {'sample_id': sample_id, 'measurement_id': row_id}\n",
    "\n",
    "        # Extract column names and values from the attributes dictionary\n",
    "        columns = ', '.join(relational_parameters.keys())\n",
    "        values = ', '.join([f\"'{v}'\" for v in relational_parameters.values()])\n",
    "\n",
    "        # Construct the SQL INSERT statement\n",
    "        sql = f\"INSERT INTO {relational_table_name} ({columns}) VALUES ({values})\"\n",
    "\n",
    "        print(sql)\n",
    "\n",
    "        # Create a cursor object using the cursor() method\n",
    "        cursor = conn.cursor()\n",
    "\n",
    "        # Execute the SQL statement\n",
    "        cursor.execute(sql)\n",
    "\n",
    "        cursor.execute('COMMIT')\n",
    "\n",
    "        cursor.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## main loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each file:\n",
    "\n",
    "1. Load it\n",
    "\n",
    "2. Separate the samples in it\n",
    "\n",
    "3. Save each isolated sample\n",
    "\n",
    "4. Save them to the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(original_paths)):\n",
    "    # Get the original path and ID\n",
    "    original_path = original_paths[i]\n",
    "    original_id = original_ids[i]\n",
    "    original_measurementtype_id = original_measurementtype_ids[i]\n",
    "    original_sample_name = original_sample_names[i]\n",
    "    number_of_samples = len(original_sample_name)\n",
    "\n",
    "    #load the volume\n",
    "    volume = io.load_tif(original_path)\n",
    "\n",
    "    #isolate the samples\n",
    "    isolated_volumes = sample_isolater.isolate_samples(volume, number_of_samples)\n",
    "\n",
    "    for j,isolated_volume in enumerate(isolated_volumes):\n",
    "\n",
    "        folder_name = saving_folder / original_sample_name[j]\n",
    "\n",
    "        print(f\"Saving isolated volume for sample {original_sample_name[j]} in folder {folder_name}\")\n",
    "        \n",
    "        # #save the volume\n",
    "        # #save it in the parent folder of it with the name aligned_90rotleft_reslicebottom.tif\n",
    "        # save_path = original_path.parent / f\"aligned_90rotright_reslicetop.tif\"\n",
    "        # #save in the path\n",
    "        # io.save_tif(save_path, volume)\n",
    "\n",
    "        # #update the database\n",
    "        # load_measurement(volume,save_path,original_id,original_measurementtype_id,original_sample_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = isolated_volumes[0]\n",
    "\n",
    "print(a.shape)\n",
    "\n",
    "print(a.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(a[-1,:,:], cmap='gray')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prepUTvsXCT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
