{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tifffile\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "import os\n",
    "import pandas as pd\n",
    "import sys\n",
    "sys.path.append(r'\\\\192.168.10.106\\imdea\\DataDriven_UT_AlbertoVicente\\10_code\\UTvsXCT-preprocessing')\n",
    "import dbtools as db\n",
    "from preprocess_tools import io, sample_isolater"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Database conection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to the database\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    conn = db.connect()\n",
    "    print(\"Connected to the database\")\n",
    "except Exception as error:\n",
    "    print(error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have to load the data from the database to get:\n",
    "\n",
    "1. The file ids to use them as parent measurement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measurements file paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original path: \\\\192.168.10.106\\imdea\\DataDriven_UT_AlbertoVicente\\02_XCT_data\\Juan Ignacio\\medidas\\JI_4+5+7+8\\volumen_eq, ID: [22 22 22 22] Measurement type ID: 2 Sample names: ['JI_4' 'JI_5' 'JI_7' 'JI_8']\n"
     ]
    }
   ],
   "source": [
    "original_paths = [Path(r'\\\\192.168.10.106\\imdea\\DataDriven_UT_AlbertoVicente\\02_XCT_data\\Juan Ignacio\\medidas\\JI_4+5+7+8\\volumen_eq')]\n",
    "\n",
    "measurements_table = db.relation_metadata('measurements','samples','sample_measurements')\n",
    "\n",
    "parent_id_column = 'measurementtype_id_measurement'\n",
    "\n",
    "saving_folder = Path(r'\\\\192.168.10.106\\imdea\\DataDriven_UT_AlbertoVicente\\02_XCT_data\\Juan Ignacio\\probetas')\n",
    "\n",
    "# for each original path, get the id_measurement where file_path_measurement is equal to the str of the original path\n",
    "\n",
    "original_ids = []\n",
    "original_measurementtype_ids = []\n",
    "original_sample_names = []\n",
    "\n",
    "for original_path in original_paths:\n",
    "    original_path_str = str(original_path)\n",
    "    original_id = measurements_table.loc[measurements_table['file_path_measurement'] == original_path_str, 'id_measurement'].values\n",
    "    original_measurementtype_id = measurements_table.loc[measurements_table['file_path_measurement'] == original_path_str, parent_id_column].values[0]\n",
    "    original_sample_name = measurements_table.loc[measurements_table['file_path_measurement'] == original_path_str, 'name_sample'].values\n",
    "    original_ids.append(original_id)\n",
    "    original_measurementtype_ids.append(original_measurementtype_id)\n",
    "    original_sample_names.append(original_sample_name)\n",
    "    print(f\"Original path: {original_path_str}, ID: {original_id}\", \n",
    "          f\"Measurement type ID: {original_measurementtype_id}\",\n",
    "          f\"Sample names: {original_sample_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Database loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_measurement(file,file_path,parent_id,measurementtype_id,sample_names):\n",
    "\n",
    "    parent_id_column = 'measurementtype_id'\n",
    "\n",
    "    main_parameters = {'file_path':file_path,parent_id_column:measurementtype_id,'parent_measurement_id':parent_id}\n",
    "\n",
    "    # metadata\n",
    "\n",
    "    #for each parameter of the measurement a metadata has to be created\n",
    "\n",
    "    metadata_parameters = []\n",
    "\n",
    "    #dimensions\n",
    "    metadata_parameters.append({'key':'height', 'value':str(file.shape[0]), 'type':'cardinal'})\n",
    "\n",
    "    metadata_parameters.append({'key':'width', 'value':str(file.shape[1]), 'type':'cardinal'})\n",
    "\n",
    "    metadata_parameters.append({'key':'depth', 'value':str(file.shape[2]), 'type':'cardinal'})\n",
    "\n",
    "    #dtype\n",
    "\n",
    "    metadata_parameters.append({'key':'dtype', 'value':str(file.dtype), 'type':'nominal'})\n",
    "\n",
    "    #############################################################################################\n",
    "\n",
    "    #MANUAL PARAMETERS\n",
    "\n",
    "    #file type\n",
    "\n",
    "    metadata_parameters.append({'key':'file_type', 'value':'folder', 'type':'nominal'})\n",
    "\n",
    "    #aligned\n",
    "\n",
    "    metadata_parameters.append({'key':'aligned', 'value':'False', 'type':'boolean'})\n",
    "\n",
    "    #equalized\n",
    "\n",
    "    metadata_parameters.append({'key':'equalized', 'value':'True', 'type':'boolean'})\n",
    "\n",
    "    #axes\n",
    "    metadata_parameters.append({'key':'axes', 'value':'x,y,z', 'type':'nominal'})\n",
    "\n",
    "    print('Parameters to be inserted: ')\n",
    "    for key, value in main_parameters.items():\n",
    "        print(f\"-    {key}: {value}\")\n",
    "\n",
    "    table_name = 'measurements'\n",
    "\n",
    "    # Extract column names and values from the attributes dictionary\n",
    "    columns = ', '.join(main_parameters.keys())\n",
    "    values = ', '.join([f\"'{v}'\" for v in main_parameters.values()])\n",
    "\n",
    "    # Construct the SQL INSERT statement\n",
    "    sql = f\"INSERT INTO {table_name} ({columns}) VALUES ({values})\"\n",
    "\n",
    "    print(sql)\n",
    "\n",
    "    # Create a cursor object using the cursor() method\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    # Execute the SQL statement\n",
    "    cursor.execute(sql)\n",
    "\n",
    "    cursor.execute('COMMIT')\n",
    "\n",
    "    cursor.close()\n",
    "\n",
    "    data = db.get_data(table_name)\n",
    "\n",
    "    data[data['file_path_measurement'] == str(file_path)]\n",
    "\n",
    "    row_id = data['id_measurement'].values[-1]\n",
    "\n",
    "    metadata_table_name =  table_name[:-1] + '_metadata'\n",
    "\n",
    "    for attributes in metadata_parameters:\n",
    "\n",
    "        attributes[table_name[:-1] + '_id'] = row_id\n",
    "\n",
    "        # Extract column names and values from the attributes dictionary\n",
    "        columns = ', '.join(attributes.keys())\n",
    "        values = ', '.join([f\"'{v}'\" for v in attributes.values()])\n",
    "\n",
    "        # Construct the SQL INSERT statement\n",
    "        sql = f\"INSERT INTO {metadata_table_name} ({columns}) VALUES ({values})\"\n",
    "\n",
    "        print(sql)\n",
    "\n",
    "        # Create a cursor object using the cursor() method\n",
    "        cursor = conn.cursor()\n",
    "\n",
    "        # Execute the SQL statement\n",
    "        cursor.execute(sql)\n",
    "\n",
    "        cursor.execute('COMMIT')\n",
    "\n",
    "        cursor.close()\n",
    "    \n",
    "    samples_data = db.get_data_metadata('samples')\n",
    "\n",
    "    #get the ids of the samples in sample_names\n",
    "    samples_data = samples_data[samples_data['name_sample'].isin(sample_names)]\n",
    "\n",
    "    sample_ids = samples_data['id_sample'].values.tolist()\n",
    "\n",
    "    relational_table_name = 'sample_measurements'\n",
    "\n",
    "    for sample_id in sample_ids:\n",
    "\n",
    "        relational_parameters = {'sample_id': sample_id, 'measurement_id': row_id}\n",
    "\n",
    "        # Extract column names and values from the attributes dictionary\n",
    "        columns = ', '.join(relational_parameters.keys())\n",
    "        values = ', '.join([f\"'{v}'\" for v in relational_parameters.values()])\n",
    "\n",
    "        # Construct the SQL INSERT statement\n",
    "        sql = f\"INSERT INTO {relational_table_name} ({columns}) VALUES ({values})\"\n",
    "\n",
    "        print(sql)\n",
    "\n",
    "        # Create a cursor object using the cursor() method\n",
    "        cursor = conn.cursor()\n",
    "\n",
    "        # Execute the SQL statement\n",
    "        cursor.execute(sql)\n",
    "\n",
    "        cursor.execute('COMMIT')\n",
    "\n",
    "        cursor.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## main loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each file:\n",
    "\n",
    "1. Load it\n",
    "\n",
    "2. Separate the samples in it\n",
    "\n",
    "3. Save each isolated sample\n",
    "\n",
    "4. Save them to the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress:   7%|â–‹         | 228/3224 [00:06<01:23, 35.71it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      7\u001b[39m number_of_samples = \u001b[38;5;28mlen\u001b[39m(original_sample_name)\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m#load the volume\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m volume = \u001b[43mio\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload_tif\u001b[49m\u001b[43m(\u001b[49m\u001b[43moriginal_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m#isolate the samples\u001b[39;00m\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# isolated_volumes = sample_isolater.isolate_samples(volume, number_of_samples)\u001b[39;00m\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m j,isolated_volume \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(isolated_volumes):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m\\\\192.168.10.106\\imdea\\DataDriven_UT_AlbertoVicente\\10_code\\UTvsXCT-preprocessing\\preprocess_tools\\io.py:107\u001b[39m, in \u001b[36mload_tif\u001b[39m\u001b[34m(path)\u001b[39m\n\u001b[32m    104\u001b[39m \u001b[38;5;66;03m# Check if the path is a directory or a file\u001b[39;00m\n\u001b[32m    105\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m os.path.isdir(path):\n\u001b[32m    106\u001b[39m     \u001b[38;5;66;03m# If it's a directory, read all TIFF files in the directory\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m107\u001b[39m     volume = \u001b[43mread_sequence\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    108\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m os.path.isfile(path):\n\u001b[32m    109\u001b[39m     \u001b[38;5;66;03m# If it's a file, read the single TIFF file\u001b[39;00m\n\u001b[32m    110\u001b[39m     volume = tifffile.imread(path)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m\\\\192.168.10.106\\imdea\\DataDriven_UT_AlbertoVicente\\10_code\\UTvsXCT-preprocessing\\preprocess_tools\\io.py:28\u001b[39m, in \u001b[36mread_sequence\u001b[39m\u001b[34m(folder_path)\u001b[39m\n\u001b[32m     26\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m tqdm(total=total_files, desc=\u001b[33m\"\u001b[39m\u001b[33mProgress\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m pbar:\n\u001b[32m     27\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m i, file_path \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(tiff_files):\n\u001b[32m---> \u001b[39m\u001b[32m28\u001b[39m         slice_data = \u001b[43mtifffile\u001b[49m\u001b[43m.\u001b[49m\u001b[43mimread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     29\u001b[39m         volume.append(slice_data)\n\u001b[32m     31\u001b[39m         \u001b[38;5;66;03m# Update progress\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\alberto.vicente\\.conda\\envs\\prepUTvsXCT\\Lib\\site-packages\\tifffile\\tifffile.py:1207\u001b[39m, in \u001b[36mimread\u001b[39m\u001b[34m(files, selection, aszarr, key, series, level, squeeze, maxworkers, buffersize, mode, name, offset, size, pattern, axesorder, categories, imread, imreadargs, sort, container, chunkshape, chunkdtype, axestiled, ioworkers, chunkmode, fillvalue, zattrs, multiscales, omexml, out, out_inplace, _multifile, _useframes, **kwargs)\u001b[39m\n\u001b[32m   1204\u001b[39m     files = files[\u001b[32m0\u001b[39m]\n\u001b[32m   1206\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(files, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(files, Sequence):\n\u001b[32m-> \u001b[39m\u001b[32m1207\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mTiffFile\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1208\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfiles\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1209\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1210\u001b[39m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1211\u001b[39m \u001b[43m        \u001b[49m\u001b[43moffset\u001b[49m\u001b[43m=\u001b[49m\u001b[43moffset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1212\u001b[39m \u001b[43m        \u001b[49m\u001b[43msize\u001b[49m\u001b[43m=\u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1213\u001b[39m \u001b[43m        \u001b[49m\u001b[43momexml\u001b[49m\u001b[43m=\u001b[49m\u001b[43momexml\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1214\u001b[39m \u001b[43m        \u001b[49m\u001b[43m_multifile\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_multifile\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1215\u001b[39m \u001b[43m        \u001b[49m\u001b[43m_useframes\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_useframes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1216\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mis_flags\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1217\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m tif:\n\u001b[32m   1218\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m aszarr:\n\u001b[32m   1219\u001b[39m             \u001b[38;5;28;01massert\u001b[39;00m key \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, \u001b[38;5;28mint\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\alberto.vicente\\.conda\\envs\\prepUTvsXCT\\Lib\\site-packages\\tifffile\\tifffile.py:4235\u001b[39m, in \u001b[36mTiffFile.__init__\u001b[39m\u001b[34m(self, file, mode, name, offset, size, omexml, _multifile, _useframes, _parent, **is_flags)\u001b[39m\n\u001b[32m   4232\u001b[39m     \u001b[38;5;28mself\u001b[39m._omexml = omexml\n\u001b[32m   4233\u001b[39m     \u001b[38;5;28mself\u001b[39m.is_ome = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m4235\u001b[39m fh = \u001b[43mFileHandle\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moffset\u001b[49m\u001b[43m=\u001b[49m\u001b[43moffset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[43m=\u001b[49m\u001b[43msize\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4236\u001b[39m \u001b[38;5;28mself\u001b[39m._fh = fh\n\u001b[32m   4237\u001b[39m \u001b[38;5;28mself\u001b[39m._multifile = \u001b[38;5;28;01mTrue\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m _multifile \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(_multifile)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\alberto.vicente\\.conda\\envs\\prepUTvsXCT\\Lib\\site-packages\\tifffile\\tifffile.py:14611\u001b[39m, in \u001b[36mFileHandle.__init__\u001b[39m\u001b[34m(self, file, mode, name, offset, size)\u001b[39m\n\u001b[32m  14609\u001b[39m \u001b[38;5;28mself\u001b[39m._close = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m  14610\u001b[39m \u001b[38;5;28mself\u001b[39m._lock = NullContext()\n\u001b[32m> \u001b[39m\u001b[32m14611\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m  14612\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m._fh \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\alberto.vicente\\.conda\\envs\\prepUTvsXCT\\Lib\\site-packages\\tifffile\\tifffile.py:14628\u001b[39m, in \u001b[36mFileHandle.open\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m  14626\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._mode \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m {\u001b[33m'\u001b[39m\u001b[33mrb\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mr+b\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mwb\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mxb\u001b[39m\u001b[33m'\u001b[39m}:\n\u001b[32m  14627\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33minvalid mode \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m._mode\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m)\n\u001b[32m> \u001b[39m\u001b[32m14628\u001b[39m \u001b[38;5;28mself\u001b[39m._file = \u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrealpath\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m  14629\u001b[39m \u001b[38;5;28mself\u001b[39m._dir, \u001b[38;5;28mself\u001b[39m._name = os.path.split(\u001b[38;5;28mself\u001b[39m._file)\n\u001b[32m  14630\u001b[39m \u001b[38;5;28mself\u001b[39m._fh = \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;28mself\u001b[39m._file, \u001b[38;5;28mself\u001b[39m._mode, encoding=\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen ntpath>:726\u001b[39m, in \u001b[36mrealpath\u001b[39m\u001b[34m(path, strict)\u001b[39m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "for i in range(len(original_paths)):\n",
    "    # Get the original path and ID\n",
    "    original_path = original_paths[i]\n",
    "    original_id = original_ids[i]\n",
    "    original_measurementtype_id = original_measurementtype_ids[i]\n",
    "    original_sample_name = original_sample_names[i]\n",
    "    number_of_samples = len(original_sample_name)\n",
    "\n",
    "    #load the volume\n",
    "    volume = io.load_tif(original_path)\n",
    "\n",
    "    #isolate the samples\n",
    "    isolated_volumes = sample_isolater.isolate_samples(volume, number_of_samples)\n",
    "\n",
    "    for j,isolated_volume in enumerate(isolated_volumes):\n",
    "\n",
    "        folder_name = saving_folder / original_sample_name[j]\n",
    "\n",
    "        print(f\"Saving isolated volume for sample {original_sample_name[j]} in folder {folder_name}\")\n",
    "        \n",
    "        # #save the volume\n",
    "        # #save it in the parent folder of it with the name aligned_90rotleft_reslicebottom.tif\n",
    "        # save_path = original_path.parent / f\"aligned_90rotright_reslicetop.tif\"\n",
    "        # #save in the path\n",
    "        # io.save_tif(save_path, volume)\n",
    "\n",
    "        # #update the database\n",
    "        # load_measurement(volume,save_path,original_id,original_measurementtype_id,original_sample_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prepUTvsXCT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
